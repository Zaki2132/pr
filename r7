body = {
    "filters": [],
    "page": 0,
    "size": 100
}

assets = []

while True:
    response = requests.post(url, headers=headers, json=body)
    if response.status_code != 200:
        print("Erreur:", response.status_code, response.text)
        break

    data = response.json()
    assets.extend(data.get("resources", []))

    if data.get("page", 0) >= data.get("totalPages", 1) - 1:
        break

    body["page"] += 1

print(f"Total assets récupérés : {len(assets)}")



import csv

# Choisis les champs à exporter
fields = ["id", "ip", "last_scan_start", "last_scan_end"]

with open("assets.csv", "w", newline='', encoding='utf-8') as f:
    writer = csv.DictWriter(f, fieldnames=fields)
    writer.writeheader()

    for asset in assets:
        row = {field: asset.get(field, "") for field in fields}
        writer.writerow(row)

print("Export terminé : assets.csv")
