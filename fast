import requests
import csv
from concurrent.futures import ThreadPoolExecutor, as_completed

API_KEY = "raoid7"  # Remplace par ta vraie clé
URL = "https://eu.api.insight.rapid7.com/vm/v4/integration/assets"
HEADERS = {
    "Authorization": f"ApiKey {API_KEY}",
    "Content-Type": "application/json",
    "Accept": "application/json"
}

# === Fonction pour récupérer une page précise ===
def fetch_page(p, size=500):
    body = {"page": p, "size": size}
    response = requests.post(URL, headers=HEADERS, json=body)
    if response.status_code == 200:
        data = response.json()
        return data.get("data", [])
    else:
        print(f"❌ Erreur page {p} : {response.status_code}")
        return []

# === Parallélisation correcte ===
def fetch_all_assets_parallel(total_pages, workers=8):
    assets = []
    with ThreadPoolExecutor(max_workers=workers) as executor:
        futures = {executor.submit(fetch_page, page): page for page in range(total_pages)}
        for future in as_completed(futures):
            page = futures[future]
            try:
                batch = future.result()
                assets.extend(batch)
                print(f"✅ Page {page} récupérée : {len(batch)} assets")
            except Exception as e:
                print(f"⚠ Erreur sur la page {page} : {e}")
    return assets

# === Export CSV complet ===
def export_to_csv(data, filename="assets_parallel.csv"):
    if not data:
        print("Aucune donnée à exporter.")
        return

    all_keys = set()
    for item in data:
        all_keys.update(item.keys())

    with open(filename, "w", newline='', encoding="utf-8") as f:
        writer = csv.DictWriter(f, fieldnames=sorted(all_keys))
        writer.writeheader()
        for item in data:
            writer.writerow(item)

    print(f"✅ Export terminé dans {filename}")

# === Lancement ===
if _name_ == "_main_":
    check = requests.post(URL, headers=HEADERS, json={"page": 0, "size": 1})
    metadata = check.json().get("metadata", {})
    total_pages = metadata.get("totalPages", 1)
    print(f"➡ Total de pages à récupérer : {total_pages}")

    assets = fetch_all_assets_parallel(total_pages, workers=8)
    print(f"\n✅ Total assets récupérés : {len(assets)}")
    export_to_csv(assets)
