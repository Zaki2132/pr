import requests
import csv
import os

API_KEY = "raoid7"  # Remplace par ta vraie clé API
BASE_URL = "https://eu.api.insight.rapid7.com"
HEADERS = {
    "Authorization": f"ApiKey {API_KEY}",
    "Content-Type": "application/json",
    "Accept": "application/json"
}

# Endpoints cibles
ENDPOINTS = {
    "assets": "/vm/v4/integration/assets",
    "scans": "/vm/v4/integration/scan",
    "scan_engines": "/vm/v4/integration/scan/engine",
    "sites": "/vm/v4/integration/sites",
    "vulnerabilities": "/vm/v4/integration/vulnerabilities"
}

# Export en CSV
def export_to_csv(data_list, name):
    if not data_list:
        print(f"Aucune donnée pour {name}")
        return

    all_keys = set()
    for item in data_list:
        all_keys.update(item.keys())

    filename = f"{name}.csv"
    with open(filename, "w", newline='', encoding="utf-8") as f:
        writer = csv.DictWriter(f, fieldnames=sorted(all_keys))
        writer.writeheader()
        for item in data_list:
            writer.writerow(item)

    print(f"✅ Exporté {len(data_list)} lignes dans {filename}")

# Fonction générique pour récupérer des données paginées
def fetch_paginated_data(endpoint, method="POST"):
    url = BASE_URL + endpoint
    data_list = []
    page = 0
    size = 100
    while True:
        body = {"page": page, "size": size}
        if method == "POST":
            response = requests.post(url, headers=HEADERS, json=body)
        else:
            response = requests.get(url, headers=HEADERS, params=body)

        if response.status_code != 200:
            print(f"❌ Erreur sur {endpoint} : {response.status_code}")
            print(response.text)
            break

        data = response.json()
        items = data.get("data", []) or data.get("resources", [])
        data_list.extend(items)

        # Pagination condition
        if data.get("page", page) >= data.get("totalPages", 1) - 1:
            break
        page += 1
    return data_list

# Lancer extraction pour tous les endpoints
def extract_all():
    for name, endpoint in ENDPOINTS.items():
        print(f"\n📥 Extraction des {name}...")
        method = "POST" if "scan" not in name else "GET"  # certains endpoints utilisent GET
        data = fetch_paginated_data(endpoint, method=method)
        export_to_csv(data, name)

if __name__ == "__main__":
    extract_all()







import requests

API_KEY = "raoid7"  # Remplace par la vraie clé complète
url = "https://eu.api.insight.rapid7.com/vm/v4/integration/assets"
headers = {
    "Authorization": f"ApiKey {API_KEY}",
    "Content-Type": "application/json",
    "Accept": "application/json"
}

assets = []
page = 0
size = 100  # max recommandé

while True:
    body = {"page": page, "size": size}
    response = requests.post(url, headers=headers, json=body)

    if response.status_code != 200:
        print("Erreur:", response.status_code)
        print(response.text)
        break

    data = response.json()
    batch = data.get("data", [])  # ou "resources", selon l’API
    if not batch:
        break

    assets.extend(batch)
    print(f"Page {page} récupérée : {len(batch)} assets")

    if data.get("page", 0) >= data.get("totalPages", 1) - 1:
        break

    page += 1

print(f"✅ Total assets récupérés : {len(assets)}")

